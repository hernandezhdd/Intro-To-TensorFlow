{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroToTF_Week2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hernandezhdd/Intro-To-TensorFlow/blob/main/IntroToTF_Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laEIXUkAD5l3"
      },
      "source": [
        "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "\n",
        "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
        "\n",
        "Some notes:\n",
        "1. It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
        "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
        "\n",
        "I've started the code for you below -- how would you finish it? \n",
        "\n",
        "**Things to Note:**\n",
        "1. When coding the `class myCallback`, Python 3 will run into an error\n",
        "```python\n",
        "TypeError: '>' not supported between instances of 'NoneType' and 'float'\n",
        "```\n",
        "when using the code\n",
        "```python\n",
        "if(logs.get('accuracy')>0.99):\n",
        "```\n",
        "\n",
        "For Python 3, use the following equivalent code line\n",
        "\n",
        "```python\n",
        "if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "```\n",
        "\n",
        "2. You can run the notebook using TensorFlow 2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zz2BWsKD5l3"
      },
      "source": [
        "#!pip install tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSQbQybFD5l4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ea8b7a-b1d5-4d92-d874-2d71ac2edf51"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEHcB3kqyHZ6"
      },
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist():\n",
        "    # Please write your code only where you are indicated.\n",
        "    # please do not remove # model fitting inline comments.\n",
        "\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "          print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "          self.model.stop_training = True\n",
        "    \n",
        "    # YOUR CODE SHOULD END HERE\n",
        "\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "    \n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    x_train = x_train/255\n",
        "    x_test = x_test/255\n",
        "\n",
        "    callbacks = myCallback()\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "                     tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "                     tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                     tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks]\n",
        "    )\n",
        "    # model fitting\n",
        "    \n",
        "    return history.epoch, history.history['accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6yc7gViD5l5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81251ce7-586f-41e2-eb0f-bbd4d18f1056"
      },
      "source": [
        "a, b = train_mnist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2241 - accuracy: 0.9353\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0915 - accuracy: 0.9723\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0622 - accuracy: 0.9809\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0428 - accuracy: 0.9861\n",
            "Epoch 5/10\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9902\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0319 - accuracy: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSWImrhUD5l5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af90f3cd-196b-4bfe-8a4b-40ff7857210a"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9353333115577698,\n",
              " 0.9722999930381775,\n",
              " 0.9808833599090576,\n",
              " 0.986133337020874,\n",
              " 0.9902166724205017]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}